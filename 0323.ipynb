{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mecab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-69cb8533029f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmecab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mecab' is not defined"
     ]
    }
   ],
   "source": [
    "mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩\tワガハイ\t吾輩\t名詞-代名詞-一般\t\t\n",
      "は\tハ\tは\t助詞-係助詞\t\t\n",
      "猫\tネコ\t猫\t名詞-一般\t\t\n",
      "で\tデ\tだ\t助動詞\t特殊・ダ\t連用形\n",
      "ある\tアル\tある\t助動詞\t五段・ラ行アル\t基本形\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "text = \"吾輩は猫である\"\n",
    "# 形態素解析の結果をChasenの出力方式で表示\n",
    "t = MeCab.Tagger(\"-Ochasen\")\n",
    "result = t.parse(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吾輩\\tワガハイ\\t吾輩\\t名詞-代名詞-一般\\t\\t\\nは\\tハ\\tは\\t助詞-係助詞\\t\\t\\n猫\\tネコ\\t猫\\t名詞-一般\\t\\t\\nで\\tデ\\tだ\\t助動詞\\t特殊・ダ\\t連用形\\nある\\tアル\\tある\\t助動詞\\t五段・ラ行アル\\t基本形\\nEOS\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 形態素解析の結果を確認\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吾輩', 'ワガハイ', '吾輩', '名詞-代名詞-一般', '', '']\n",
      "['は', 'ハ', 'は', '助詞-係助詞', '', '']\n",
      "['猫', 'ネコ', '猫', '名詞-一般', '', '']\n",
      "['で', 'デ', 'だ', '助動詞', '特殊・ダ', '連用形']\n",
      "['ある', 'アル', 'ある', '助動詞', '五段・ラ行アル', '基本形']\n"
     ]
    }
   ],
   "source": [
    "# 形態素解析の結果を、改行を区切りとして行ごとに分割\n",
    "results = result.splitlines()\n",
    "\n",
    "# EOSの行は対象外とする\n",
    "for res in results[:-1]:\n",
    "    res_split = res.split(\"\\t\")\n",
    "    print(res_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['子供', 'が', '走る'], ['車', 'が', '走る'], ['子供', 'の', '脇', 'を', '車', 'が', '走る']]\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "documents = [\"子供が走る\",\"車が走る\",\"子供の脇を車が走る\"]\n",
    "words_list = []\n",
    "\n",
    "#　形態素解析の結果をChasenの出力形式で表示\n",
    "t = MeCab.Tagger(\"-Ochasen\")\n",
    "\n",
    "# 各文に形態素解析を実行\n",
    "for s in documents:\n",
    "    s_parsed = t.parse(s)\n",
    "    words_s = []\n",
    "    \n",
    "    #　各文の形態素をリストにまとめる\n",
    "    for line in s_parsed.splitlines()[:-1]:\n",
    "        words_s.append(line.split(\"\\t\")[0])\n",
    "    words_list.append(words_s)\n",
    "\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'子供': 0, 'が': 1, '走る': 2, '車': 3, 'の': 4, '脇': 5, 'を': 6}\n"
     ]
    }
   ],
   "source": [
    "# 生成する辞書\n",
    "word2int = {}\n",
    "i = 0\n",
    "\n",
    "# 各文書の単語のリストに対して処理を反復\n",
    "for words in words_list:\n",
    "    # 文書内の各単語に対して処理を反復\n",
    "    for word in words:\n",
    "        # 単語が辞書に含まれていなければ追加して対応する整数を割り当てる\n",
    "        if word not in word2int:\n",
    "            word2int[word] = i\n",
    "            i += 1\n",
    "\n",
    "print(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# BoWを計算し、文書X単語の行列を生成\n",
    "bow = np.zeros((len(words_list), len(word2int)), dtype=np.int)\n",
    "\n",
    "# 各行の単語を抽出し、単語の出現回数をカウント\n",
    "for i,words in enumerate(words_list):\n",
    "    for word in words:\n",
    "        bow[i, word2int[word]] += 1\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>子供</th>\n",
       "      <th>が</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>脇</th>\n",
       "      <th>を</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   子供  が  走る  車  の  脇  を\n",
       "0   1  1   1  0  0  0  0\n",
       "1   0  1   1  1  0  0  0\n",
       "2   1  1   1  1  1  1  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(bow, columns=list(word2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(7 unique tokens: ['が', '子供', '走る', '車', 'の']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# 辞書を作成する\n",
    "word2int_gs = corpora.Dictionary(words_list)\n",
    "print(word2int_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'が': 0, '子供': 1, '走る': 2, '車': 3, 'の': 4, 'を': 5, '脇': 6}\n"
     ]
    }
   ],
   "source": [
    "# 単語と整数の対応\n",
    "print(word2int_gs.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 1番目の文書に含まれる単語の出現回数をカウント\n",
    "print(word2int_gs.doc2bow(words_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import matutils\n",
    "\n",
    "# Bag of Wordsを計算し、文書X単語の行列を生成\n",
    "bow_gs = np.array([matutils.corpus2dense([word2int_gs.doc2bow(words)], \n",
    "                                        num_terms=len(word2int)).T[0] for words in words_list]).astype(np.int)\n",
    "print(bow_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  子供  走る  車  の  を  脇\n",
       "0  1   1   1  0  0  0  0\n",
       "1  1   0   1  1  0  0  0\n",
       "2  1   1   1  1  1  1  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasのデータフレームに変換\n",
    "bow_gs_df = pd.DataFrame(bow_gs, columns=list(word2int_gs.values()))\n",
    "bow_gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['子供 が 走る' '車 が 走る' '子供 の 脇 を 車 が 走る']\n"
     ]
    }
   ],
   "source": [
    "# 単語をスペース区切りで並べた文を生成\n",
    "words_split = np.array([\" \".join(words) for words in words_list])\n",
    "print(words_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Bag of Wordsを計算\n",
    "vectorizer = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\")\n",
    "bow_vec = vectorizer.fit_transform(words_split)\n",
    "\n",
    "# NumPy配列に変換\n",
    "bow_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['が', 'の', 'を', '子供', '脇', '走る', '車']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>が</th>\n",
       "      <th>子供</th>\n",
       "      <th>走る</th>\n",
       "      <th>車</th>\n",
       "      <th>の</th>\n",
       "      <th>を</th>\n",
       "      <th>脇</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   が  子供  走る  車  の  を  脇\n",
       "0  1   1   1  0  0  0  0\n",
       "1  1   0   1  1  0  0  0\n",
       "2  1   1   1  1  1  1  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 0]\n",
      " [1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# TFとしてBowを使用\n",
    "tf = bow_gs\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.28768207 0.         0.28768207 0.69314718 0.69314718\n",
      " 0.69314718]\n"
     ]
    }
   ],
   "source": [
    "# IDFを計算\n",
    "idf = np.log((bow_gs.shape[0] + 1) / (np.sum(bow_gs, axis=0, keepdims=0) + 1))\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52284231 0.67325467 0.52284231 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.52284231 0.         0.52284231 0.67325467 0.         0.\n",
      "  0.        ]\n",
      " [0.26806191 0.34517852 0.26806191 0.34517852 0.45386827 0.45386827\n",
      "  0.45386827]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDFを計算\n",
    "tf_idf = tf * (idf + 1)\n",
    "tf_idf_normalized = tf_idf / np.sqrt(np.sum(tf_idf**2, axis=1, keepdims=True))\n",
    "print(tf_idf_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52284231 0.67325467 0.52284231 0.         0.         0.\n",
      "  0.        ]\n",
      " [0.52284231 0.         0.52284231 0.67325467 0.         0.\n",
      "  0.        ]\n",
      " [0.26806191 0.34517852 0.26806191 0.34517852 0.45386827 0.45386827\n",
      "  0.45386827]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# TfidfTransformerクラスをインスタンス化\n",
    "tfidf = TfidfTransformer(use_idf=True, norm=\"l2\", smooth_idf=True)\n",
    "\n",
    "# TF-IDFを算出\n",
    "print(tfidf.fit_transform(bow_gs).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "def fibonacci(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fibonacci(n - 1) + fibonacci(n - 2)\n",
    "    \n",
    "for i in range(8):\n",
    "    print(fibonacci(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
